number of topics to be fit these values are used to encode type/topic counts as count/topic pairs in a single dirichlet alpha alpha is the distribution over topics prior on per topic multinomial distribution over words indexed by <feature index topic index> indexed by <topic index> for dirichlet estimation histogram of document sizes histogram of document/topic counts indexed by <topic index sequence position index> exact power of 2 otherwise add an extra bit err workerrunnable worker runnable thread + numtopics num topics + topics + topicbits topic bits + topic bits + 				 tobinarystring to binary topicmask topic mask + topic mask clear the topic totals clear the type/topic counts only looking at the entries before the first 0 entry the format for these arrays is the topic in the rightmost bits the count in the remaining left bits since the count is in the high bits sorting desc by the numeric value of the guarantees that higher counts will be before the lower counts start by assuming that the is either empty or is in sorted descending order here we are only adding counts so if we find an existing location with the topic we only need to ensure that it is not larger than its left neighbor new value is 1 so we don't have to worry about sorting except by topic suffix which doesn't matter now ensure that the is still sorted by bubbling this value up initialize the smoothing only sampling bucket initialize the cached coefficients using only smoothing these values will be selectively replaced in documents with non zero counts in particular topics /*
				 if doc % 10000 == 0 {
				 out processing doc + doc 
				 }
				*/ /* currently ignored */ 		populate topic counts build an that densely lists the topics that have non zero counts record the total number of non zero topics 		initialize 		 initialize the topic count/beta sampling bucket initialize cached coefficients and the topic/beta normalizing constant 	initialize the normalization constant for the b * n_{t|d} term 	update the coefficients for the non zero topics 	iterate 	 iterate over the positions words in the document 	remove 	 remove this token from all counts remove this topic's contribution to the normalizing constants decrement the local doc/topic counts maintain the dense index if we are deleting the old topic first get to the dense location associated with the old topic we know it's in there somewhere so we don't need bounds checking shift all remaining dense indices to the left decrement the global topic count totals add the old topic's contribution back into the normalizing constants reset the cached coefficient for this topic now go over the type/topic counts decrementing where appropriate and calculating the score for each topic at the same time we're decrementing and adding up the sampling weights at the same time but decrementing may require us to reorder the topics so after we're done here look at this cell in the again shift the reduced value to the right if necessary 	make 	 make sure it actually gets set topictermcount++ topic term count++ bubble the new value up if necessary betatopiccount++ beta topic count++ smoothingonlycount++ smoothing only count++ move to the position for the new topic which may be the first empty position if this is a new topic for this word index should now be set to the position of the new topic which may be an empty cell at the end of the list inserting a new topic guaranteed to be in order w r t count if not topic bubble the increased value left if necessary todo t o d o is this appropriate throw new illegalstateexception illegal state workerrunnable worker runnable new topic not sampled assert newtopic new topic != 1 			put 			 put that new topic into the counts if this is a new topic for this document add the topic to the dense index first find the point where we should insert the new topic by going to the end which is the only reason we're keeping track of the number of non zero topics and working backwards 	update the coefficients for the non zero topics update the document topic count histogram for dirichlet estimation 	clean 	 clean up our mess reset the coefficients to values with only 	smoothing the next doc will update its own non zero topics 