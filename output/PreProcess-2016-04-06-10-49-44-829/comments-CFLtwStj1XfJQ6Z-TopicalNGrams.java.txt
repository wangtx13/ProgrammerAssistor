containing featuresequencewithbigrams feature sequence with bigrams in the data field of each instance {0 t 1} the topic index indexed by <document index sequence index> {0 1} the bigram status indexed by <document index sequence index> todo t o d o make this boolean? number of unique unigrams number of unique bigrams total number of word occurrences totalngram total ngram total number of tokens currently generated as bigrams only used for progress messages doctopic doc topic indexed by <document index topic index> used to calculate p x|w t ngramcount ngram count indexed by <feature index ngram status topic index> used to calculate p w|t and p w|t w topicword topic word and topicngramword topic ngram word indexed by <feature index topic index> index by <bifeature index topic index> sumwords sum words indexed by <topic index> sumngramwords sum ngram words indexed by <feature index topic index> where the later is the conditioned word smoothing over the choice of topic smoothing over the choice of unigram words smoothing over the choice of bigram words smoothing over the choice of unigram/bigram generation todo t o d o clean this up initialize with random assignments of tokens to topics and finish allocating this topics and this tokens randomly assign tokens to topics randomly sample a topic for the word at position si if a bigram is allowed at position si then sample a gram status for it /* one iteration of gibbs sampling across all documents */ loop over every word in the corpus indexed by topic index length==numtopics length==num topics length==numtopics*2 length==num topics*2 joint topic/gram sampling xxx doclen doc len = onedoctokens one doc tokens length iterate over the positions words in the document if bitype == 1 out biblock +si+ at +unialphabet +uni alphabet lookupobject lookup type nextgram next gram = si == doclen doc len 1 ? 1 onedoctokens one doc tokens getbiindexatposition get bi index at position si+1 == 1 ? 0 1 remove this token from all counts build a distribution over topics for this token additional term is constance across all topics sample a topic assignment from this distribution put that new topic into the counts bigram is possible remove this token from all counts build a joint distribution over topics and ngram status for this token just using this variable as an index into ti*2+gram the unigram outcome the bigram outcome sample a topic assignment from this distribution put that new topic into the counts put that new topic into the counts unigrams bigrams /*
			wp = new wordprob word prob numbitypes num bitypes 
			int bisum = 0 
			for wi = 0 wi < numbitypes num bitypes wi++ {
				wp wi = new wordprob word prob wi bitypetopiccounts bitype topic counts wi ti 
				bisum += bitypetopiccounts bitype topic counts wi ti 
			}
			arrays 
			}
			 arrays sort wp 
			numtoprint 
			num to print = math min wp length numwords num words 
			if usenewlines use new lines {
				system {
				 out \ntopic \n topic +ti+ bigrams 
				for i = 0 i < numtoprint num to print i++ 
					system 
					 out bialphabet bi alphabet lookupobject lookup wp i wi tostring to + + wp i p/bisum 
			} else {
				system {
				 out print 
				for i = 0 i < numtoprint num to print i++ 
					system 
					 out print bialphabet bi alphabet lookupobject lookup wp i wi tostring to + 
				system 
				 out 
			}
			*/ ngrams out pre sorting out post sorting +numngrams +num ngrams out print unique ngrams= +numngrams+ +num ngrams+ ngram count= +math + math round afv onenorm one norm + \n serialization just for testing recommend instead is mallet/bin/vectors2topics 