fill in the classfeaturecounts feature counts /*
		for fi = 0 fi < numfeatures num features fi++ 
			featurecounts 
			feature counts fi = 0 
		for ci = 0 ci < numclasses num classes ci++ {
			classcounts {
			class counts ci = 0 
			for fi = 0 fi < numfeatures num features fi++ 
				classfeaturecounts 
				class feature counts ci fi = 0 
		}
		*/ xxx note that this ignores uncertainly labeled instances! out fi= +featureindex+ +feature index+ ni= +numinstances+ +num instances+ fc= +featurecounts +feature counts featureindex feature index + i= +i let c_i be a random variable on {c_i !c_i} per entropy of feature f_j = h c_i|f_j h c_i|f_j = p c_i|f_j log p c_i|f_j p !c_i|f_j log p !c_i|f_j first calculate the per entropy not conditioned on any feature and store it in classcounts counts calculate per infogain of each feature and store it in classfeaturecounts feature counts assert sum == featurecounts feature counts fi calculate the {ci !ci} entropy given that the feature does occur calculate the {ci !ci} entropy given that the feature does not occur print selected features 