the training instances and their topic assignments the alphabet for the input data the alphabet for the topics the largest topic seen so far the current number of topics the size of the vocabulary prior prior on per topic multinomial distribution over words statistics needed for sampling indexed by <feature index topic index> indexed by <topic index> the number of documents that contain at least one token with a given topic keep track of the number of docs with at least one token in a given topic loop over every document in the corpus occasionally print more information 		populate topic counts store a list of all the topics that currently 	iterate 	 iterate over the positions words in the document grab the relevant row from our two dimensional 	remove 	 remove this token from all counts was this the only token of this topic in the doc? was this the only doc with this topic? this should be the very last token get rid of the topic this is the last in the doc but the topic still there is at least one other token in this doc with this topic now calculate and add up the scores for each topic for this word first do the topics that currently add the weight for a new topic choose a random point between 0 and the sum of all topic scores figure out which topic contains that point this is not a new topic but it is new for this doc completely new topic first generate an for displaying and saving results 