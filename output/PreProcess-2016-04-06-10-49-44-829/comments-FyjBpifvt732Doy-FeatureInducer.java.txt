/* where will the new features get extracted in the pipe? */ only one of the following two will be non xxx could perhaps build a hash value for each feature that measures its distribution over instances and avoid conjunctions of features that are *exact* duplicates with this hash value for i = gg numlocations num locations 200 i < gg numlocations num locations i++ out i= +i+' '+double '+ tostring to gg getvalueatrank get value at rank i + ' ' + gg getobjectatrank get at rank i tostring to out prevent it from searching through all of gg2 mingain min gain = gg getvalueatrank get value at rank maxbeam*2 max beam*2 no there are so many duplicate features that it ends up only adding a few each round mingain min gain = negative_infinity just use a constant anything less than this must not have enough support in the data mingain min gain = 5 xxx temporarily remove all feature conjunction pruning out featureinducer feature inducer temporarily not pruning any feature conjunctions from consideration fsmin fs min = fsmax fs max = mingain min gain = negative_infinity conjunctions = new beam for b = 0 b < beam b++ conjunctions b = gg getindexatrank get index at rank b allow memory to be freed there are no more new features we could add because they all have no more gain than the features we started with first disjunct above so that we also add singleton features that are currently masked out xxx if addmaskedfeatures add masked features == we should still check the mask so we don't add and print features that are already unmasked make sure that the new conjunction doesn't contain duplicate features don't add features with exactly the same gain value they are probably an exactly overlapping duplicate xxx note that this might actually increase over fitting! don't add new conjunctions that have no more gain than any of their constituents out skipping feature that adds no gain +newfeaturevalue+' +new feature value+' '+s if we have a feature mask be sure to include this new feature xxx also print the gradient here if the feature already out atomic feature rank +i+ at index +index a new atomic feature added to the featureselection feature selection don't add features with exactly the same gain value they are probably an exactly overlapping duplicate xxx note that this might actually increase over fitting! this ilist classifications numnewfeatures num new features 200 numnewfeatures num new features this ilist classifications numnewfeatures num new features 200 500 this must be run on test instance lists before they can be transduced because we have to add the right feature combinations! out induced features for instance # +i serialization 