these function as default selections for the kind of estimator used added to support incremental training these are the counts formed after naivebayes naive bayes training note that these are *not* the estimates passed to the naivebayes naive bayes classifier rather the estimates are formed from these counts we could break these five fields out into a inner a value of 1 means don't do any document length normalization if this style of incremental training is successful the following members should probably be moved up into incrementalclassifiertrainer incremental classifier trainer needed to construct a new classifier extracted from instancelist instance list must be the same for all calls to incrementaltrain incremental train extracted from instancelist instance list must be the same for all calls to incrementaltrain incremental train forget all the previous sufficient statistics counts train a new classifier based on this data initialize and check instance variables as necessary incrementally add the counts of this new training data estimate multinomials and a new naive bayes classifier note that unlike maxent max ent naivebayes naive bayes is immutable so we create a new one each time incrementally add the counts of this new training instance initialize the alphabets make sure the alphabets match initialize or check the instancepipe instance pipe make sure that this pipes match is this really necessary?? i don't think so but it could be confusing to have each classifier have a different pipe? akm 1/08 target alphabet grew increase size of our multinomial copy over old values initialize new expanded space handle unlabeled instances by skipping them skip instances that have no features present make the document have counts that sum to doclengthnormalization doc length normalization i e if 20 it would be as if the document had 20 words out naivebayestrainer naive bayes trainer me increment + labelweight label weight * instanceweight instance weight this relies on labelweight label weight summing to 1 over all labels me print debugging alphabetcarrying alphabet carrying serialization serialversionuid serial uid is overriden to prevent innocuous changes in this from making the serialization mechanism think the external format has changed default selections for the kind of estimator used these are the counts formed after naivebayes naive bayes training pipe and alphabets default selections for the kind of estimator used these are the counts formed after naivebayes naive bayes training pipe and alphabets 