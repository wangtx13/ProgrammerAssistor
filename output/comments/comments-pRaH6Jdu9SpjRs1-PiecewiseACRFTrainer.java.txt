/* vectors that contain the counts of features observed in the
 training data maps
  maps
 clique template x feature number => count
 */ /* vectors that contain the expected value over the
 * labels of all the features have seen the training data
 * but not the training labels 
 */ /* initialize constraints and expectations 
 * to have the same dimensions as weights but to
 * be all zero 
 */ do the defaults first and now the others /* allocate for weights constraints and expectations */ /*
	if cacheunrolledgraphs cache unrolled graphs {
	unrolledgraphs {
	unrolled graphs = new unrolledgraph unrolled graph numinstances num instances 
	}
*/ /* negate initialvalue initial value and finalvalue value because the are in
 * terms of weights not values 
 */ functions for unit tests to get constraints and expectations i'm too lazy to make a deep copy callers should not modify these /* instance values must either always or never be included in
 * the total values we can't just sometimes skip a value
 * because it is infinite that off the total values 
 * we only allow an instance to have infinite value if it happens
 * from the start we don't compute the value for the instance
 * after the first round if any other instance has infinite
 * value after that it is an */ /* we could initialize bitset with one slot for every
 * instance but it is *probably* cheaper not to taking the
 * time hit to allocate the space if a bit becomes
 * necessary */ /* clear the sufficient statistics that we are about to fill */ /* fill in expectations for each instance */ /* incorporate gaussian prior on this means
 that for each weight we will add w^2 / 2 * variance to the
 log probability */ /* compute marginals for each clique */ happens if all nodes are pruned /* save the expected value of each feature for when we
 compute the gradient */ /*					throw new illegalstateexception
						  illegal state exception
						 value is nan na n in acrf a c r f getvalue get value instance +i 
*/ /* index into current element of cachedgradient cached gradient */ first do gradient wrt defaultweights default weights now do other weights computed below /* a parameter may be set to infinity by an external user 
 * we set gradient to 0 because the parameter's value can
 * never change anyway and it will mess up future calculations
 * on the matrix */ for each assigment to the clique xxx slow s l o w this will need to be sparsified optimizableacrf optimizable a c r f 