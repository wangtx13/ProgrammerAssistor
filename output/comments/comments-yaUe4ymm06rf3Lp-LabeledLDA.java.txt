model output options model hyperparameters the training instances and their topic assignments the alphabet for the input data this alphabet stores the meanings of the labels/topics the alphabet for the topics the number of topics requested the size of the vocabulary prior dirichlet alpha alpha is the distribution over topics prior on per topic multinomial distribution over words an to put the topic counts for the current document initialized locally below defined here to avoid garbage collection overhead indexed by <document index topic index> statistics needed for sampling indexed by <feature index topic index> indexed by <topic index> we have one topic for every possible label skip some lines starting with # that describe the format and specify hyperparameters this is the difference between the dense type topic representation used here and the sparse used in paralleltopicmodel parallel topic model loop over every document in the corpus occasionally print more information 		populate topic counts 	iterate 	 iterate over the positions words in the document grab the relevant row from our two dimensional 	remove 	 remove this token from all counts now calculate and add up the scores for each topic for this word here's where the math happens! note that overall performance is dominated by what you do in this loop choose a random point between 0 and the sum of all topic scores figure out which topic contains that point make sure we actually sampled a topic put that new topic into the counts the likelihood of the model is a combination of a dirichlet multinomial for the words in each topic and a dirichlet multinomial for the topics in each document the likelihood function of a dirichlet multinomial is 	 gamma sum_i alpha_i 	 prod_i gamma alpha_i + n_i 	prod_i gamma alpha_i 	 gamma sum_i alpha_i + n_i so the log likelihood is 	loggamma 	log gamma sum_i alpha_i loggamma log gamma sum_i alpha_i + n_i + 	 sum_i loggamma log gamma alpha_i + n_i loggamma log gamma alpha_i do the documents first add the parameter sum term subtract the count + parameter sum term and the topics count the number of type topic pairs reuse this as a pointer for displaying and saving results serialization instance lists i don't want to directly inherit from paralleltopicmodel parallel topic model because the two implementations treat the type topic counts differently instead simulate a standard parallel topic model by copying over the appropriate data structures 