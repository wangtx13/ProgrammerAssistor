gsc changing field access to make this extensible various values from crf c r f acting as indicators of when we need to re calculate expectations and values to getvalue get value because weights' values changed re calculate to getvaluegradient get value gradient because weights' values changed set up cachedgradient cached gradient = new densevector dense vector numparameters num this resets and values that may have been in expectations and constraints reallocatesufficientstatistics reallocate sufficient statistics this is unfortunately necessary b/c cachedvalue cached value cachedvaluestale cached value stale not in same place! set the constraints by running forward backward with the *output label sequence provided* thus restricting it to only those paths that agree with the label sequence zero the constraints reset constraints to zero before we fill them again out constraint gathering on instance +i+ of +ilist size 		system 		 out testing value and gradient 		testoptimizable 		 test optimizable testvalueandgradientcurrentparameters test value and gradient current this todo t o d o move these implementations into crf c r f and put here stubs that call them! log probability of the training sequence labels and fill in expectations instance values must either always or never be included in the total values we can't just sometimes skip a value because it is infinite this off the total values reset expectations to zero before we fill them again count the number of instances that have infinite weight calculate the value of each instance and also fill in expectations out labeledweight labeled weight = +labeledweight +labeled weight out unlabeledweight unlabeled weight = +unlabeledweight +unlabeled weight here weight is log conditional probability correct label sequence out instance +ii+ crf c r f maximizablecrf maximizable c r f getweight get weight = +weight weights are log probabilities and we want to a log probability the cached value is not up to date it was calculated for a different set of crf c r f weights cachedvalue cached value will soon no longer be stale crf print get the value of all the all the labels also filling in expectations at the same time incorporate prior on hyperbolic prior gaussian prior gsc make sure the prior gives a correct value gsc changing from assertnotnan assert not na n to assertnotnanorinfinite assert not na n or infinite crf are allowed to have infinite values priorgradient prior gradient is parameter/gaussianpriorvariance parameter/gaussian prior variance gradient is constraint expectation + priorgradient prior gradient == expectation constraint priorgradient prior gradient gradient points up hill i e in the direction of higher value cachedgradient cached gradient will soon no longer be stale this will fill in the this expectation updating it if necessary gradient is constraints expectations + prior we do this by expectations constraints prior this implements the in the above comment xxx show the feature with maximum gradient todo t o d o is something like this negation still necessary????? up to now we've been calculating the weightgradient weight gradient take the opposite to get the valuegradient value gradient cachedgradient cached gradient timesequals times equals 1 0 point uphill what the heck was this!? if buffer length != this numparameters num buffer = new this numparameters num arrays fill buffer 0 0 arraycopy cachedgradie cached gradie 0 buffer 0 2*crf initialweights initial weights length todo t o d o for now just copy the state inital/final weights gsc adding these get/set for the prior serialization of maximizablecrf maximizable c r f 