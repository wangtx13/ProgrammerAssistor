number of batches of training set batch specific expectations constraints over whole training set value and gradient for each batch to avoid sharing set up reset expectations to zero before we fill them again count the number of instances that have infinite weight weight is log conditional probability correct label sequence weights are log probabilities and we want to a log probability get the value of all the labels for current batch also filling in expectations hyperbolic prior gaussian prior update cache crf parameters' check has to be done only once infinite values are allowed factor the constraints and the prior into the expectations of last batch gradient = constraints expectations + prior = expectations constraints prior the minus sign is factored in combinegradients combine gradients after all gradients are computed set the cached gradient from getbatchvaluegradient get batch value gradient 