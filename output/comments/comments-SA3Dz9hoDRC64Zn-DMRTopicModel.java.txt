todo t o d o consider beginning by sub sampling? train regression loop over every document in the corpus set appropriate alpha use only the default features to set the topic prior use no document features use only the default features to set the topic prior use no document features we can't use the standard score functions from maxent max ent since our features are currently in the target create a fake pipe with the features in the data and a trove hashmap of topic counts in the target put the real target in the data field and the topic counts in the target field optimize once step size too small restart with a fresh initialization to improve likelihood step size too small this sets alpha and alphasum alpha sum now cache alpha values 